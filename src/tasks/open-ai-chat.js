/**
 * @file A collection of functions for executing chat completions with the OpenAI API
 * @author Thomas J. Purk
 */

import OpenAI from "openai";
import fs from "fs";
import { zodResponseFormat } from "openai/helpers/zod";
import { responseSchema } from "./open-ai-chat-schema.js";
const openai = new OpenAI();

/**
 * @export
 * @function completeChat
 * @param {string} systemContent Sets the persona for the LLM to adopt while answering the question
 * @param {string} userContent The question to ask the LLM, is modified to include the concept name
 * @param {string} parentConcept The parent concept of the topic of interest
 * @param {string} conceptName The topic of interest to ask the LLM to answer
 * @param {string} dirCompletions The folder to save or load the result
 * @return {string} A JSON string containing the LLM's answer
 */
export async function completeChat(
  systemContent,
  userContent,
  parentConcept,
  conceptName,
  dirCompletions
) {
  // Determine if a file containing a previous chat completion already exists
  // If it does, load the data from the file rather than submitting a new
  // chat completion to the LLM.
  let targetFile = `${dirCompletions}/${parentConcept}/${conceptName}.json`;
  if (fs.existsSync(targetFile)) {
    console.log(`Loading From File: ${conceptName}`);
    return fs.readFileSync(targetFile).toString();
  } else {
    // Since there is no existing file, ask the LLM to answer the question
    userContent = userContent.replace("<name>", conceptName);
    const completion = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [
        { role: "system", content: systemContent },
        {
          role: "user",
          content: userContent,
        },
      ],
      response_format: zodResponseFormat(responseSchema[parentConcept], parentConcept),
    });

    // The core answer
    const conceptJsonString = completion.choices[0].message.content;
    console.log(
      `Generated By LLM: ${conceptName} -> Validate Name: ${conceptJsonString.substring(
        0,
        20
      )}`
    );

    // Write the LLM data to a cache file for future use
    fs.writeFileSync(targetFile, conceptJsonString);

    // Return the JSON string to the calling function.
    return conceptJsonString;
  }
}
